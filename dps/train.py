from __future__ import absolute_import
from __future__ import division
import time
from contextlib import ExitStack
import tensorflow as tf
import numpy as np
from pprint import pformat
import datetime
import shutil
import os
import pandas as pd
import dill
from collections import defaultdict
import traceback
import json
import subprocess
from tabulate import tabulate
import warnings

from dps import cfg
from dps.utils import (
    gen_seed, time_limit, Alarm, memory_usage, gpu_memory_usage, ExperimentStore,
    ExperimentDirectory, nvidia_smi, memory_limit, Config, ClearConfig, redirect_stream,
    NumpySeed, restart_tensorboard, pdb_postmortem
)
from dps.utils.tf import (
    uninitialized_variables_initializer, trainable_variables, walk_variable_scopes
)
from dps.mpi_train import MPI_MasterContext


def training_loop(exp_name='', start_time=None):
    loop = TrainingLoop(exp_name)
    return loop.run(start_time)


class EarlyStopHook(object):
    def __init__(self, patience, maximize):
        self.patience = patience
        self.maximize = maximize
        self.reset()

    def _check_trigger(self, sc):
        if self._best_stopping_criteria is None:
            return True

        if self.maximize:
            return sc > self._best_stopping_criteria
        else:
            return sc < self._best_stopping_criteria

    def check(self, stopping_criteria, step, record):
        new_best = self._check_trigger(stopping_criteria)
        if new_best:
            self._best_stopping_criteria = stopping_criteria
            self._best_step = step
            self._best_record = record.copy()

        if self.patience > 0:
            self._early_stopped = (
                self._early_stopped or (step - self._best_step > self.patience))
        return new_best, self._early_stopped

    @property
    def best(self):
        best = self._best_record.copy()
        best.update(stopping_criteria=self._best_stopping_criteria, local_step=self._best_step)
        return best

    def reset(self):
        self._best_stopping_criteria = None
        self._best_record = None
        self._best_step = None
        self._early_stopped = 0


def load_or_train(train_config, var_scope, path, target_var_scope=None, sess=None):
    """ Attempts to load variables into ``var_scope`` from checkpoint stored at ``path``.

    If said checkpoint is not found, trains a model using the function
    ``train`` and stores the resulting variables for future use.

    Returns True iff model was successfully loaded, False otherwise.

    If `target_var_scope` is not None, look for the variables under that scope name in the file
    that we load from, instead of `var_scope`.

    """
    sess = sess or tf.get_default_session()

    to_be_loaded = trainable_variables(var_scope, for_opt=False)
    if target_var_scope is not None:
        _tbl = {}
        for var in to_be_loaded:
            assert var.name.startswith(var_scope.name)
            bare_name = var.name[len(var_scope.name):]
            while bare_name.startswith('/'):
                bare_name = bare_name[1:]
            name_in_file = target_var_scope + '/' + bare_name
            _tbl[name_in_file] = var
        to_be_loaded = _tbl
    else:
        to_be_loaded = {v.name: v for v in to_be_loaded}

    saver = tf.train.Saver(to_be_loaded)

    if path is not None:
        os.makedirs(os.path.dirname(path), exist_ok=True)

    success = False
    try:
        saver.restore(sess, path)
        success = True
    except tf.errors.NotFoundError:
        with ExitStack() as stack:
            stack.enter_context(ClearConfig())
            stack.enter_context(train_config.copy(save_path=path))

            output = training_loop(var_scope.name)

            stem = os.path.splitext(path)[0]
            shutil.copyfile(output.path_for('stdout'), stem + '.stdout')
            shutil.copyfile(output.path_for('stderr'), stem + '.stderr')

        saver.restore(sess, path)
    return success


class TrainingLoop(object):
    """ A training loop.

    The behaviour of the training loop depends on the context stack that is active when it is
    run (i.e. `run` method is called), not the one that is active when it is created.

    Parameters
    ----------
    exp_name: str
        Name of the experiment, used as a prefix when creating a directory for storing data
        generated by the training run.

    """
    def __init__(self, exp_name=''):
        self.exp_name = exp_name or cfg.exp_name
        self.start_time = None

    @property
    def time_remaining(self):
        if cfg.max_time is None or cfg.max_time <= 0:
            return np.inf
        else:
            elapsed_time = time.time() - self.start_time
            return cfg.max_time - elapsed_time

    def edit_remaining_stage(self, idx, stage_config):
        if len(self.curriculum_remaining) < idx+1:
            for i in range(idx+1 - len(self.curriculum_remaining)):
                self.curriculum_remaining.append(dict())

        self.curriculum_remaining[idx].update(stage_config)

    def timestamp(self, message):
        print("{} ({}, {:.2f}s elapsed, {:.2f}s remaining)".format(
            message,
            datetime.datetime.now(),
            time.time() - self.start_time,
            self.time_remaining))

    def run(self, start_time):
        """ Run the training loop.

        Parameters
        ----------
        start_time: int
            Start time (in seconds since epoch) for measuring elapsed time for
            purposes of interrupting the training loop.

        """
        if start_time is None:
            start_time = time.time()
        self.start_time = start_time

        self.timestamp("Entering TrainingLoop.run")

        prepare_func = cfg.get("prepare_func", None)
        if callable(prepare_func):
            prepare_func()  # Modify the config in arbitrary ways before training
        else:
            try:
                prepare_funcs = list(prepare_func)
            except (TypeError, ValueError):
                pass
            else:
                for f in prepare_funcs:
                    if callable(f):
                        f()

        self.curriculum = cfg.curriculum + []

        if cfg.seed is None or cfg.seed < 0:
            cfg.seed = gen_seed()

        # Create a directory to store the results of the training session.
        self.experiment_store = ExperimentStore(os.path.join(cfg.local_experiments_dir, cfg.env_name))
        exp_dir = self.experiment_store.new_experiment(
            self.exp_name, cfg.seed, add_date=1, force_fresh=1, update_latest=cfg.update_latest)
        self.exp_dir = exp_dir
        cfg.path = exp_dir.path

        breaker = "-" * 40
        header = "{}\nREADME.md - {}\n{}\n\n\n".format(breaker, os.path.basename(exp_dir.path), breaker)
        readme = header + (cfg.readme if cfg.readme else "") + "\n\n"

        with open(exp_dir.path_for('README.md'), 'w') as f:
            f.write(readme)

        self.data = _TrainingLoopData(exp_dir)
        self.data.setup()

        frozen_data = None

        with ExitStack() as stack:
            if cfg.pdb:
                stack.enter_context(pdb_postmortem())
                print("`pdb` is turned on, so forcing setting robust=False")
                cfg.robust = False

            stack.enter_context(redirect_stream('stdout', self.data.path_for('stdout'), tee=cfg.tee))
            stack.enter_context(redirect_stream('stderr', self.data.path_for('stderr'), tee=cfg.tee))

            stack.enter_context(warnings.catch_warnings())
            warnings.simplefilter('once')

            print("\n\n" + "=" * 80)
            self.timestamp("Starting training run (name={})".format(self.exp_name))

            print("\nDirectory for this training run is {}.".format(exp_dir.path))

            stack.enter_context(NumpySeed(cfg.seed))
            print("\nSet numpy random seed to {}.\n".format(cfg.seed))

            limiter = time_limit(
                self.time_remaining, verbose=True,
                timeout_callback=lambda limiter: print("Training run exceeded its time limit."))

            self.mpi_context = MPI_MasterContext(cfg.get('n_procs', 1), exp_dir)

            try:
                with limiter:
                    self._run()

            finally:
                self.data.summarize()

                self.timestamp("Done training run (name={})".format(self.exp_name))
                print("=" * 80)
                print("\n\n")

                frozen_data = self.data.freeze()

        self.timestamp("Leaving TrainingLoop.run")

        return frozen_data

    def _run(self):
        print(cfg.to_string())

        threshold_reached = True
        self.global_step = 0
        self.n_global_experiences = 0
        self.curriculum_remaining = self.curriculum + []
        self.curriculum_complete = []

        stage_idx = 0
        while self.curriculum_remaining:
            print("\n" + "=" * 50)
            self.timestamp("Starting stage {}".format(stage_idx))
            print("\n")

            if cfg.start_tensorboard:
                if cfg.start_tensorboard == "local":
                    tb_path = self.exp_dir.path
                else:
                    try:
                        n_latest = int(cfg.start_tensorboard)
                        tb_path = self.experiment_store.isolate_n_latest(n_latest)
                    except (ValueError, TypeError):
                        tb_path = self.experiment_store.path

                restart_tensorboard(tb_path, cfg.tbport, cfg.reload_interval)

            stage_config = self.curriculum_remaining.pop(0)
            stage_config = Config(stage_config)

            self.data.start_stage(stage_idx, stage_config)

            with ExitStack() as stack:

                # --------------- Stage set-up -------------------

                print("\n" + "-" * 10 + " Stage set-up " + "-" * 10)

                print("\nNew config values for this stage are: \n{}\n".format(pformat(stage_config)))
                stack.enter_context(stage_config)

                stage_prepare_func = cfg.get("stage_prepare_func", None)
                if callable(stage_prepare_func):
                    stage_prepare_func()  # Modify the stage config in arbitrary ways before starting stage

                self.mpi_context.start_stage()

                # Configure and create session and graph for stage.
                session_config = tf.ConfigProto()
                session_config.intra_op_parallelism_threads = cfg.get('intra_op_parallelism_threads', 0)
                session_config.inter_op_parallelism_threads = cfg.get('inter_op_parallelism_threads', 0)
                session_config.log_device_placement = cfg.get('log_device_placement', 0)

                if cfg.use_gpu:
                    per_process_gpu_memory_fraction = getattr(cfg, 'per_process_gpu_memory_fraction', None)
                    if per_process_gpu_memory_fraction:
                        session_config.gpu_options.per_process_gpu_memory_fraction = per_process_gpu_memory_fraction

                    gpu_allow_growth = getattr(cfg, 'gpu_allow_growth', None)
                    if gpu_allow_growth:
                        session_config.gpu_options.allow_growth = gpu_allow_growth

                if cfg.use_gpu:
                    print("Using GPU if available.")
                    print("Using {}% of GPU memory.".format(
                        100 * session_config.gpu_options.per_process_gpu_memory_fraction))
                    print("Allowing growth of GPU memory: {}".format(session_config.gpu_options.allow_growth))

                graph = tf.Graph()
                sess = tf.Session(graph=graph, config=session_config)

                # This HAS to come after the creation of the session, otherwise
                # it allocates all GPU memory if using the GPU.
                print("\nAvailable devices: ")
                from tensorflow.python.client import device_lib
                print(device_lib.list_local_devices())

                if not cfg.use_gpu:
                    print("Not using GPU.")
                    stack.enter_context(graph.device("/cpu:0"))

                stack.enter_context(graph.as_default())
                stack.enter_context(sess)
                stack.enter_context(sess.as_default())

                # Set the seed for the stage. Notice we generate a new tf seed for each stage.
                tf_seed = gen_seed()
                print("Setting tensorflow seed to generated seed: {}\n".format(tf_seed))
                tf.set_random_seed(tf_seed)

                # Set limit on CPU RAM for the stage
                cpu_ram_limit_mb = cfg.get("cpu_ram_limit_mb", None)
                if cpu_ram_limit_mb is not None:
                    stack.enter_context(memory_limit(cfg.cpu_ram_limit_mb))

                print("Building env...\n")

                # Maybe build env
                if stage_idx == 0 or not cfg.preserve_env:
                    if getattr(self, 'env', None):
                        self.env.close()

                    self.env = cfg.build_env()

                if hasattr(self.env, "print_memory_footprint"):
                    self.env.print_memory_footprint()

                print("\nDone building env.\n")
                print("Building updater...\n")

                if cfg.n_procs > 1:
                    updater = cfg.get_updater(self.env, mpi_context=self.mpi_context)
                else:
                    updater = cfg.get_updater(self.env)

                updater.stage_idx = stage_idx
                updater.exp_dir = self.exp_dir

                updater.build_graph()
                print("\nDone building updater.\n")

                walk_variable_scopes(max_depth=cfg.variable_scope_depth)

                # Maybe initialize network weights.
                # Let a *path_specification* be one of three things:
                #     1. An integer specifying a stage to load the best hypothesis from.
                #     2. A string of format: "stage_idx,kind" where `stage_idx` specifies a stage to load from
                #        and `kind` is either "final" or "best", specifying whether to load final or best
                #        hypothesis from that stage.
                #     3. A path on the filesystem that gives a prefix for a tensorflow checkpoint file to load from.
                #
                # Then cfg.load_path can either be a path_specification itself, in which case all variables
                # in the network will be loaded from that path_specification, or a dictionary mapping from
                # variable scope names to path specifications, in which case all variables in each supplied
                # variable scope name will be loaded from the path_specification paired with that scope name.
                load_path = cfg.load_path
                if load_path is not None:
                    if isinstance(load_path, str) or isinstance(load_path, int):
                        load_path = {"": load_path}

                    load_path = dict(load_path)

                    # Sort in increasing order, so that it if one variable scope lies within another scope,
                    # the outer scope gets loaded before the inner scope, rather than having the outer scope
                    # wipe out the inner scope.
                    items = sorted(load_path.items())

                    for var_scope, path in items:
                        variables = {v.name: v for v in trainable_variables(var_scope, for_opt=False)}
                        if not variables:
                            print("No variables to load in scope {}.".format(str(var_scope)))
                            continue

                        saver = tf.train.Saver(variables)

                        load_stage, kind = None, None

                        if isinstance(path, int):
                            load_stage = path
                            kind = "best"
                        elif isinstance(path, str):
                            try:
                                split = path.split(',')
                                load_stage = int(split[0])
                                kind = 'best' if len(split) > 1 else split[1]
                                assert kind in 'best final'.split(), "path={}".format(path)
                            except Exception:
                                load_stage, kind = None, None

                        if load_stage is not None:
                            if stage_idx == 0:
                                print(
                                    "Not loading var scope \"{}\" from stage {}, "
                                    "currently in stage 0.".format(var_scope, load_stage))
                                continue
                            else:
                                key = kind + '_path'
                                completed_history = self.data.history[:-1]
                                path = completed_history[load_stage][key]

                        path = os.path.realpath(path)

                        saver.restore(tf.get_default_session(), path)

                        print("Loading var scope \"{}\" from {}.".format(var_scope, path))
                else:
                    print("Using a fresh set of weights, not loading anything.")

                tf.train.get_or_create_global_step()
                sess.run(uninitialized_variables_initializer())
                sess.run(tf.assert_variables_initialized())

                for hook in cfg.hooks:
                    assert isinstance(hook, Hook)
                    hook.start_stage(self, updater, stage_idx)

                if cfg.render_step > 0 and cfg.render_hook is not None:
                    cfg.render_hook.start_stage(self, updater, stage_idx)

                # Prevent memory leaks, no ops can be added to the graph after this point
                graph.finalize()

                threshold_reached = False
                reason = None

                try:
                    # --------------- Run stage -------------------

                    start = time.time()
                    phys_memory_before = memory_usage(physical=True)
                    gpu_memory_before = gpu_memory_usage()

                    threshold_reached, reason = self._run_stage(stage_idx, updater)

                except KeyboardInterrupt:
                    reason = "User interrupt"

                except NotImplementedError as e:
                    # There is a bug in pdb_postmortem that prevents instances of `NotImplementedError`
                    # from being handled properly, so replace it with an instance of `Exception`.
                    if cfg.robust:
                        traceback.print_exc()
                        reason = "Exception occurred ({})".format(repr(e))
                    else:
                        raise Exception("NotImplemented") from e

                except Exception as e:
                    reason = "Exception occurred ({})".format(repr(e))
                    if cfg.robust:
                        traceback.print_exc()
                    else:
                        raise

                except Alarm:
                    reason = "Time limit exceeded"
                    raise

                finally:
                    phys_memory_after = memory_usage(physical=True)
                    gpu_memory_after = gpu_memory_usage()

                    self.data.record_values_for_stage(
                        stage_duration=time.time()-start,
                        phys_memory_before_mb=phys_memory_before,
                        phys_memory_delta_mb=phys_memory_after - phys_memory_before,
                        gpu_memory_before_mb=gpu_memory_before,
                        gpu_memory_delta_mb=gpu_memory_after - gpu_memory_before
                    )

                    self.data.record_values_for_stage(reason=reason)

                    print("\n" + "-" * 10 + " Optimization complete " + "-" * 10)
                    print("\nReason: {}.\n".format(reason))

                    final_path = self.data.path_for('weights/final_for_stage_{}'.format(stage_idx))
                    final_path = cfg.get('save_path', final_path)
                    final_path = updater.save(tf.get_default_session(), final_path)
                    self.data.record_values_for_stage(final_path=final_path)

                    # --------------- Maybe render performance of best hypothesis -------------------

                    do_final_testing = (
                        "Exception occurred" not in reason
                        and reason != "Time limit exceeded"
                        and 'best_path' in self.data.current_stage_record)

                    if do_final_testing:
                        try:
                            print("\n" + "-" * 10 + " Final testing/rendering " + "-" * 10)

                            print("Best hypothesis for this stage was found on "
                                  "step (l: {best_local_step}, g: {best_global_step}) "
                                  "with stopping criteria ({sc_name}) of {best_stopping_criteria}.".format(
                                      sc_name=self.stopping_criteria_name, **self.data.current_stage_record))

                            best_path = self.data.current_stage_record['best_path']
                            print("Loading best hypothesis for this stage "
                                  "from file {}...".format(best_path))
                            updater.restore(sess, best_path)

                            test_record = updater.evaluate(cfg.batch_size, mode="test")

                            for hook in cfg.hooks:
                                if hook.call_per_timestep and hook.final:
                                    hook_record = hook.step(self, updater)

                                    if hook_record:
                                        assert len(hook_record) == 1
                                        for k, d in dict(hook_record).items():
                                            test_record.update(d)

                            self.data.record_values_for_stage(
                                **{'_test_' + k: v for k, v in test_record.items()})

                            if cfg.render_final and cfg.render_step > 0 and cfg.render_hook is not None:
                                print("Rendering...")
                                cfg.render_hook(updater)
                                print("Done rendering.")

                        except BaseException:
                            print("Exception occurred while performing final testing/rendering: ")
                            traceback.print_exc()

                    else:
                        print("\n" + "-" * 10 + " Skipping final testing/rendering " + "-" * 10)

                    # --------------- Finish up the stage -------------------

                    self.data.end_stage(updater.n_updates)

                    print("\n" + "-" * 10 + " Running end-of-stage hooks " + "-" * 10 + "\n")
                    for hook in cfg.hooks:
                        hook.end_stage(self, stage_idx)

                    print()
                    self.timestamp("Done stage {}".format(stage_idx))
                    print("=" * 50)

                    stage_idx += 1
                    self.curriculum_complete.append(stage_config)

                if not (threshold_reached or cfg.power_through):
                    print("Failed to reach stopping criteria threshold on stage {} "
                          "of the curriculum, terminating.".format(stage_idx))
                    break

    def _run_stage(self, stage_idx, updater):
        """ Run main training loop for a stage of the curriculum. """

        threshold_reached = False
        reason = "NotStarted"

        # Parse stopping criteria, set up early stopping
        stopping_criteria = cfg.get("stopping_criteria", None)
        if not stopping_criteria:
            stopping_criteria = updater.stopping_criteria

        if isinstance(stopping_criteria, str):
            stopping_criteria = stopping_criteria.split(",")

        self.stopping_criteria_name = stopping_criteria[0]
        if "max" in stopping_criteria[1]:
            self.maximize_sc = True
        elif "min" in stopping_criteria[1]:
            self.maximize_sc = False
        else:
            raise Exception("Ambiguous stopping criteria specification: {}".format(stopping_criteria[1]))

        early_stop = EarlyStopHook(patience=cfg.patience, maximize=self.maximize_sc)

        # Start stage
        print("\n" + "-" * 10 + " Training begins " + "-" * 10)
        self.timestamp("")
        print()

        total_hooks_time = 0.0
        time_per_hook = 0.0

        total_eval_time = 0.0
        time_per_eval = 0.0

        total_train_time = 0.0
        time_per_example = 0.0
        time_per_update = 0.0

        n_eval = 0

        while True:
            # Check whether to keep training
            if updater.n_updates >= cfg.max_steps:
                reason = "Maximum number of steps-per-stage reached"
                break

            if updater.n_experiences >= cfg.max_experiences:
                reason = "Maximum number of experiences-per-stage reached"
                break

            local_step = updater.n_updates
            global_step = self.global_step

            evaluate = (local_step % cfg.eval_step) == 0
            display = (local_step % cfg.display_step) == 0
            render = (cfg.render_step > 0
                      and (local_step % cfg.render_step) == 0
                      and (local_step > 0 or cfg.render_first))

            if display or render or evaluate or local_step % 100 == 0:
                print("\n{} Starting step {} {}\n".format("-" * 40, local_step, "-" * 40))

            data_to_store = []

            # --------------- Run hooks -------------------

            hooks_start = time.time()

            for hook in cfg.hooks:
                if hook.call_per_timestep:
                    run_hook = local_step == 0 and hook.initial
                    run_hook |= local_step > 0 and local_step % hook.n == 0

                    if run_hook:
                        hook_record = hook.step(self, updater, local_step)

                        if hook_record:
                            data_to_store.extend(dict(hook_record).items())

            hooks_duration = time.time() - hooks_start

            if render and cfg.render_hook is not None:
                print("Rendering...")
                cfg.render_hook(updater)
                print("Done rendering.")

            # --------------- Possibly evaluate -------------------

            if evaluate:
                print("Evaluating...")
                eval_start_time = time.time()
                val_record = updater.evaluate(cfg.batch_size, mode="val")
                eval_duration = time.time() - eval_start_time
                print("Done evaluating")

                val_record["duration"] = eval_duration

                n_eval += 1
                total_eval_time += eval_duration
                time_per_eval = total_eval_time / n_eval

                data_to_store.append(("val", val_record))

                if self.stopping_criteria_name not in val_record:
                    print("Stopping criteria {} not in record returned "
                          "by updater, using 0.0.".format(self.stopping_criteria_name))

                stopping_criteria = val_record.get(self.stopping_criteria_name, 0.0)
                new_best, stop = early_stop.check(stopping_criteria, local_step, val_record)

                if new_best:
                    print("Storing new best on step (l={}, g={}), "
                          "constituting (l={}, g={}) experiences, "
                          "with stopping criteria ({}) of {}.".format(
                              local_step, global_step,
                              updater.n_experiences, self.n_global_experiences,
                              self.stopping_criteria_name, stopping_criteria))

                    best_path = self.data.path_for(
                        'weights/best_of_stage_{}'.format(stage_idx))
                    best_path = cfg.get('save_path', best_path)

                    weight_start = time.time()
                    best_path = updater.save(tf.get_default_session(), best_path)

                    print("Done saving weights, took {} seconds".format(time.time() - weight_start))

                    self.data.record_values_for_stage(
                        best_path=best_path, best_global_step=global_step)
                    self.data.record_values_for_stage(
                        **{'best_' + k: v for k, v in early_stop.best.items()})

                if stop:
                    print("Early stopping triggered.")
                    reason = "Early stopping triggered"
                    break

                if self.maximize_sc:
                    threshold_reached = stopping_criteria >= cfg.threshold
                else:
                    threshold_reached = stopping_criteria <= cfg.threshold

                if threshold_reached:
                    reason = "Stopping criteria threshold reached"
                    break

            # --------------- Perform an update -------------------

            if cfg.do_train:
                if local_step % 100 == 0:
                    print("Running update step {}...".format(local_step))

                update_start_time = time.time()

                _old_n_experiences = updater.n_experiences

                update_record = updater.update(cfg.batch_size)

                update_duration = time.time() - update_start_time
                update_record["train"]["duration"] = update_duration

                if local_step % 100 == 0:
                    print("Done update step, took {} seconds.".format(update_duration))

                if local_step % 100 == 0:
                    start = time.time()
                    update_record["train"]["memory_physical_mb"] = memory_usage(physical=True)
                    update_record["train"]["memory_virtual_mb"] = memory_usage(physical=False)
                    update_record["train"]["memory_gpu_mb"] = gpu_memory_usage()
                    print("Memory check duration: {}".format(time.time() - start))

                if evaluate:
                    # Only store train data as often as we evaluate, otherwise it's just too much data
                    data_to_store.extend(dict(update_record).items())

                n_experiences_delta = updater.n_experiences - _old_n_experiences
                self.n_global_experiences += n_experiences_delta

                total_train_time += update_duration
                time_per_example = total_train_time / updater.n_experiences
                time_per_update = total_train_time / updater.n_updates

                total_hooks_time += hooks_duration
                time_per_hook = total_hooks_time / updater.n_updates

            # --------------- Store data -------------------

            records = defaultdict(dict)
            for mode, r in data_to_store:
                records[mode].update(r)

            self.data.store_step_data_and_summaries(
                stage_idx, local_step, global_step,
                updater.n_experiences, self.n_global_experiences,
                **records)

            self.data.record_values_for_stage(
                time_per_example=time_per_example,
                time_per_update=time_per_update,
                time_per_eval=time_per_eval,
                time_per_hook=time_per_hook,
                n_steps=local_step,
                n_experiences=updater.n_experiences,
            )

            if display:
                print("Displaying...")
                self.data.summarize_current_stage(
                    local_step, global_step, updater.n_experiences, self.n_global_experiences)
                print("\nMy PID: {}\n".format(os.getpid()))
                print("Physical memory use: {}mb".format(memory_usage(physical=True)))
                print("Virtual memory use: {}mb".format(memory_usage(physical=False)))

                print("Avg time per update: {}s".format(time_per_update))
                print("Avg time per eval: {}s".format(time_per_eval))
                print("Avg time for hooks: {}s".format(time_per_hook))

                if cfg.use_gpu:
                    print(nvidia_smi())

            if local_step > 0 and local_step % cfg.checkpoint_step == 0:
                self.data.dump_data(local_step)

            self.global_step += 1

            # If `do_train` is False, we do no training and evaluate
            # exactly once, so only one iteration is required.
            if not cfg.do_train:
                reason = "`do_train` set to False"
                break

        return threshold_reached, reason


class FrozenTrainingLoopData(ExperimentDirectory):
    """ Interface for the on-disk data generated by a training loop.

    Parameters
    ----------
    path: str
        Path to the the directory for the experiment whose data we want to access.

    """
    def __init__(self, path):
        self.path = path.path if isinstance(path, ExperimentDirectory) else path
        self._config = None
        self._history = None

    def get_summary_path(self, mode):
        return self.path_for('summaries/' + mode, is_dir=True)

    def get_data_path(self, mode, stage_idx, local_step):
        local_path = 'data/{}/stage{}/localstep={}.csv'.format(mode, stage_idx, local_step)
        return self.path_for(local_path)

    def step_data(self, mode, stage_slice=None):
        indices = range(self.n_stages)
        if stage_slice is None:
            pass
        elif isinstance(stage_slice, int):
            indices = [indices[stage_slice]]
        elif isinstance(stage_slice, slice):
            indices = indices[stage_slice]
        else:
            start, end, *step = stage_slice
            step = step[0] if step else 1
            indices = indices[start:end:step]

        data = {}

        for stage_idx in indices:
            local_path = 'data/{}/stage{}'.format(mode, stage_idx)
            path = self.path_for(local_path)
            files = os.listdir(path) if os.path.isdir(path) else []
            for f in files:
                local_step = float(f.split('=')[1].split('.')[0])  # Filename created by `get_data_path`
                data[(stage_idx, local_step)] = pd.read_csv(os.path.join(path, f))

        data_frames = [df for _, df in sorted(data.items())]
        if data_frames:
            return pd.concat(data_frames, axis=0, ignore_index=True)
        else:
            return None

    @property
    def config(self):
        if self._config is None:
            try:
                with open(self.path_for('config.pkl'), 'rb') as f:
                    self._config = dill.load(f)
            except Exception:
                pass
            else:
                return self._config

            try:
                with open(self.path_for('config.json'), 'r') as f:
                    self._config = json.load(f)
            except Exception:
                pass
            else:
                return self._config

        return self._config

    def get_config_value(self, key):
        """ A temporary hack to deal with version inconsistencies. """
        if self.config is None:
            command = "grep \"'{}':\" < {}".format(key, self.path_for("config.txt"))
            p = subprocess.run(command, shell=True, stdout=subprocess.PIPE)

            # Get the line with the least amount of indentation.
            lines = p.stdout.decode().split('\n')
            lines = [l for l in lines if l.strip()]
            indentations = []
            for line in lines:
                n_leading_spaces = 0
                for c in line:
                    if c.isspace():
                        n_leading_spaces += 1
                    else:
                        break
                indentations.append((n_leading_spaces, line))
            smallest_indent = min(indentations)
            with_smallest = [(s, l) for s, l in indentations if s == smallest_indent[0]]
            assert len(with_smallest) == 1, with_smallest
            line = with_smallest[0][1]

            left, right = line.split(':')
            right = right.strip()[:-1]
            right = eval(right)
            return right
        else:
            return self.config[key]

    @property
    def n_stages(self):
        return len(self.history)

    @property
    def history(self):
        if self._history is None:
            try:
                with open(self.path_for('history.json'), 'r') as f:
                    self._history = json.load(f)
            except Exception:
                with open(self.path_for('history.pkl'), 'rb') as f:
                    self._history = dill.load(f)
        return self._history

    @property
    def modes(self):
        return os.listdir(self.path_for('summaries'))


class _TrainingLoopData(FrozenTrainingLoopData):
    """ Data structure used by a TrainingLoop to manage data
        throughout the experiment.

    """
    def setup(self):
        # Record training session environment for later diagnostic purposes
        self.record_environment(config=cfg)
        self.curriculum = []

        self.make_directory('weights')
        self.make_directory('plots')
        self.make_directory('data')
        self.make_directory('summaries')

        self._history = []

        self.data = defaultdict(list)
        self.summary_writers = {}

        self.stage_idx = -1

    @property
    def history(self):
        return self._history

    def start_stage(self, stage_idx, stage_config):
        self.history.append(dict(stage_idx=stage_idx, stage_config=stage_config))
        self.stage_idx = stage_idx
        self.summary_writers = {}

    def end_stage(self, local_step=None):
        self.dump_data(local_step)
        for writer in self.summary_writers.values():
            writer.close()

    def dump_data(self, local_step):
        if local_step is None:
            local_step = float("inf")  # Final dump for a stage

        for mode, data in self.data.items():
            if data:
                path = self.get_data_path(mode, self.stage_idx, local_step)

                with open(path, 'w') as f:
                    pd.DataFrame.from_records(data).to_csv(f, index=False)

                self.data[mode] = []

    def record_values_for_stage(self, d=None, **kwargs):
        """ Record values for the current stage. """
        d = d or {}
        self.current_stage_record.update(d)
        self.current_stage_record.update(kwargs)

    def store_step_data_and_summaries(
            self, stage_idx, local_step, global_step, n_local_experiences, n_global_experiences, **data):

        for mode, record in data.items():
            if not record:
                continue

            if getattr(cfg, 'store_step_data', True):
                record = record.copy()
                record.update(
                    stage_idx=stage_idx,
                    local_step=local_step,
                    global_step=global_step,
                    n_local_experiences=n_local_experiences,
                    n_global_experiences=n_global_experiences)

                self.data[mode].append(record)

            self.store_scalar_summaries(mode, record, n_global_experiences)

    def store_scalar_summaries(self, mode, record, n_global_experiences):
        # Build a summary using the Summary protocol buffer
        # See https://stackoverflow.com/questions/37902705/how-to-manually-create-a-tf-summary
        summary_values = [tf.Summary.Value(tag="all/"+k, simple_value=float(v)) for k, v in record.items()]
        summary = tf.Summary(value=summary_values)
        writer = self._get_summary_writer(mode)
        writer.add_summary(summary, n_global_experiences)

    def _get_summary_writer(self, mode):
        if mode not in self.summary_writers:
            self.summary_writers[mode] = tf.summary.FileWriter(
                self.get_summary_path(mode), flush_secs=cfg.reload_interval)
        return self.summary_writers[mode]

    @property
    def current_stage_record(self):
        return self.history[-1]

    def _finalize(self):
        """ Write all stored data to disk. """
        self.dump_data(None)

        with open(self.path_for('history.json'), 'w') as f:
            json.dump(self.history, f, default=str, indent=4, sort_keys=True)

    def freeze(self):
        self._finalize()
        return FrozenTrainingLoopData(self.path)

    def summarize_current_stage(self, local_step, global_step, n_local_experiences, n_global_experiences):
        stage_idx = self.current_stage_record['stage_idx']

        print("\n {} Summary: Stage={}, Step(l={}, g={}), Experiences(l={}, g={}) {}\n".format(
            "*" * 20, stage_idx, local_step, global_step,
            n_local_experiences, n_global_experiences, "*" * 20))

        data = defaultdict(dict)

        for k, v in sorted(self.current_stage_record.items()):
            if isinstance(v, dict):
                v = "\n" + pformat(v, indent=2)
                print("* {}: {}".format(k, v))
            elif k.endswith("_path") or not k.startswith("best_"):
                print("* {}: {}".format(k, v))
            else:
                data[k[5:]]['best'] = v

        for mode, mode_data in sorted(self.data.items()):
            if mode_data:
                record = mode_data[-1] or {}
                for k, v in sorted(record.items()):
                    if isinstance(v, dict):
                        v = "\n" + pformat(v, indent=2)
                        print("* {}_{}: {}".format(mode, k, v))
                    else:
                        data[k][mode] = v

        headers = ["key", "best"] + sorted(self.data)
        table = [
            [key] + [row.get(k, None) for k in headers[1:]]
            for key, row in sorted(data.items())]

        print(tabulate(table, headers=headers, tablefmt="psql"))

    def summarize(self):
        """ Summarize the training data.

        Parameters
        ----------
        steps: quadtuple of ints
            local_step, global_step, local_experience, global_experiences

        """
        print("\n" + "-" * 30 + " Stage-by-Stage Summary " + "-" * 30 + "\n")

        table = defaultdict(dict)

        for record in self.history:
            stage_idx = record['stage_idx']
            print("\n" + "-" * 20 + " Stage {} ".format(stage_idx) + "-" * 20)

            for k, v in sorted(record.items()):
                if isinstance(v, dict):
                    v = "\n" + pformat(v, indent=2)
                    print("* {}: {}".format(k, v))
                elif isinstance(v, str) and len(v) > 20:
                    print("* {}: {}".format(k, v))
                else:
                    table[k][stage_idx] = v

        headers = ["key"] + list(range(len(self.history)))
        table = [
            [key] + [row.get(k, None) for k in headers[1:]]
            for key, row in sorted(table.items())]

        print()
        print(tabulate(table, headers=headers, tablefmt="psql"))
        print()


class Hook(object):
    """ Hook called throughout training.

    Parameters
    ----------
    n: int
        Hook is called every n steps throughout training.
    initial: bool
        If True, this hook is called on the first step of a stage.
    final: bool
        If True, this hook is called at the end of stage, after loading
        the best hypothesis.

    """
    def __init__(self, n=None, initial=False, final=False):
        self.n = n
        self.initial = initial
        self.final = final

    @property
    def call_per_timestep(self):
        return bool(self.n)

    def _attrs(self):
        return "n initial final".split()

    def __str__(self):
        attr_string = ", ".join(
            "{}={}".format(k, getattr(self, k)) for k in self._attrs())
        return("{}({})".format(self.__class__.__name__, attr_string))

    def __repr__(self):
        return str(self)

    def start_stage(self, training_loop, updater, stage_idx):
        """ Called at the beginning of every stage. """
        pass

    def end_stage(self, training_loop, stage_idx):
        """ Called at the end of every stage, after best hypothesis has been reloaded. """
        pass

    def step(self, training_loop, updater, step_idx):
        """ May return a list of summaries and a dictionary of recorded values, similar to an updater. """
        pass

    def _print(self, s):
        print("{}: {}".format(self.__class__.__name__, s))


class ScheduleHook(Hook):
    def __init__(self, attr_name, query_name, initial_value=0.0, tolerance=0.05, base_configs=None):
        self.attr_name = attr_name
        self.query_name = query_name
        self.initial_value = initial_value

        if tolerance is None:
            tolerance = np.inf
        self.tolerance = tolerance

        if isinstance(base_configs, dict):
            base_configs = [base_configs]
        self.base_configs = base_configs or [{}]

        self.n_fragments_added = 0

        super(ScheduleHook, self).__init__()

    def _attrs(self):
        return "attr_name query_name initial_value tolerance base_configs".split()

    def _attr_value_for_fragment(self):
        raise Exception("NotImplemented")

    def start_stage(self, training_loop, updater, stage_idx):
        if stage_idx == 0:
            self.final_orig_stage = len(training_loop.curriculum) - 1

    def end_stage(self, training_loop, stage_idx):

        if stage_idx >= self.final_orig_stage:
            attr_value = self._attr_value_for_fragment(self.n_fragments_added)
            new_stages = [{self.attr_name: attr_value, **bc} for bc in self.base_configs]

            if stage_idx == self.final_orig_stage:
                self.original_performance = training_loop.data.history[-1][self.query_name]
                self._print("End of original stages, adding 1st curriculum fragment:\n{}".format(new_stages))
                for i, ns in enumerate(new_stages):
                    training_loop.edit_remaining_stage(i, ns)
                self.n_fragments_added = 1

            elif not training_loop.curriculum_remaining:
                # Check whether performance achieved on most recent stage was near that of the first stage.
                current_stage_performance = training_loop.data.history[-1][self.query_name]
                threshold = (1 + self.tolerance) * self.original_performance

                self._print("End of {}-th curriculum fragment.".format(self.n_fragments_added))
                self._print("Original <{}>: {}".format(self.query_name, self.original_performance))
                self._print("<{}> for fragment {}: {}".format(
                    self.query_name, self.n_fragments_added, current_stage_performance))
                self._print("<{}> threshold: {}".format(self.query_name, threshold))

                if current_stage_performance <= threshold:
                    self.n_fragments_added += 1
                    self._print("Threshold reached, adding {}-th "
                                "curriculum fragment:\n{}".format(self.n_fragments_added, new_stages))

                    for i, ns in enumerate(new_stages):
                        training_loop.edit_remaining_stage(i, ns)

                else:
                    self._print("Threshold not reached, ending training run")
            else:
                self._print("In the middle of the {}-th curriculum fragment.".format(self.n_fragments_added))
        else:
            self._print("Still running initial stages.")


class GeometricScheduleHook(ScheduleHook):
    def __init__(self, *args, multiplier=2.0, **kwargs):
        super(GeometricScheduleHook, self).__init__(*args, **kwargs)
        self.multiplier = multiplier

    def _attrs(self):
        return super(GeometricScheduleHook, self)._attrs() + ["multiplier"]

    def _attr_value_for_fragment(self, fragment_idx):
        return self.initial_value * (self.multiplier ** fragment_idx)


class PolynomialScheduleHook(ScheduleHook):
    def __init__(self, *args, scale=10.0, power=1.0, **kwargs):
        super(PolynomialScheduleHook, self).__init__(*args, **kwargs)
        self.scale = scale
        self.power = power

    def _attrs(self):
        return super(PolynomialScheduleHook, self)._attrs() + ["scale", "power"]

    def _attr_value_for_fragment(self, fragment_idx):
        return self.initial_value + self.scale * (fragment_idx ** self.power)
